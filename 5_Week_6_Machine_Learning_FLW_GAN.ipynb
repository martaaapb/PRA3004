{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH_fIMnXB_aI",
        "outputId": "2b7c781d-ca7c-48ef-bdbb-34e58bdc8f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-16 16:24:39--  http://www.cs.columbia.edu/CAVE/databases/pubfig/download/lfw_attributes.txt\n",
            "Resolving www.cs.columbia.edu (www.cs.columbia.edu)... 128.59.11.206\n",
            "Connecting to www.cs.columbia.edu (www.cs.columbia.edu)|128.59.11.206|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cs.columbia.edu/CAVE/databases/pubfig/download/lfw_attributes.txt [following]\n",
            "--2024-03-16 16:24:40--  https://www.cs.columbia.edu/CAVE/databases/pubfig/download/lfw_attributes.txt\n",
            "Connecting to www.cs.columbia.edu (www.cs.columbia.edu)|128.59.11.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14879205 (14M) [text/plain]\n",
            "Saving to: ‘lfw_attributes.txt’\n",
            "\n",
            "lfw_attributes.txt  100%[===================>]  14.19M  5.41MB/s    in 2.6s    \n",
            "\n",
            "2024-03-16 16:24:44 (5.41 MB/s) - ‘lfw_attributes.txt’ saved [14879205/14879205]\n",
            "\n",
            "--2024-03-16 16:24:44--  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz\n",
            "Resolving vis-www.cs.umass.edu (vis-www.cs.umass.edu)... 128.119.244.95\n",
            "Connecting to vis-www.cs.umass.edu (vis-www.cs.umass.edu)|128.119.244.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 243346528 (232M) [application/x-gzip]\n",
            "Saving to: ‘lfw-funneled.tgz’\n",
            "\n",
            "lfw-funneled.tgz    100%[===================>] 232.07M   391KB/s    in 10m 42s \n",
            "\n",
            "2024-03-16 16:35:27 (370 KB/s) - ‘lfw-funneled.tgz’ saved [243346528/243346528]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# training GANS is a slow process: be sure to switch to hardware accelerator GPU in 'change runtime type', and switch to high-RAM when prompted.\n",
        "# GAN procedure mostly taken from https://github.com/yandexdataschool/mlhep2018/\n",
        "\n",
        "# Download dataset\n",
        "!wget http://www.cs.columbia.edu/CAVE/databases/pubfig/download/lfw_attributes.txt\n",
        "!wget http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz # 233 MB!\n",
        "!tar -xf lfw-funneled.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnRedA7781oU"
      },
      "outputs": [],
      "source": [
        "# Some data-handling tools and imports\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import subprocess\n",
        "from imageio import imread\n",
        "#from scipy.misc import imresize\n",
        "#!pip install pillow\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "def fetch_lfw_dataset(attrs_name = \"lfw_attributes.txt\",\n",
        "                      images_name = \"lfw-deepfunneled\",\n",
        "                      raw_images_name = \"lfw\",\n",
        "                      use_raw=False,\n",
        "                      dx=80,dy=80,\n",
        "                      dimx=45,dimy=45):\n",
        "\n",
        "    # read attrs\n",
        "    # the header row begins with a #, which we want to ignore\n",
        "    with open(attrs_name) as attributes_file:\n",
        "        attributes_file.readline()\n",
        "        ugly_header = attributes_file.read(2)\n",
        "        assert ugly_header == \"#\\t\"\n",
        "        df_attrs = pd.read_csv(attributes_file, sep='\\t', skipinitialspace=True)\n",
        "        #print(df_attrs)\n",
        "        #print(df_attrs.columns.values.tolist())\n",
        "\n",
        "    #read photos\n",
        "    dirname = raw_images_name if use_raw else images_name\n",
        "    photo_ids = []\n",
        "    initial_depth = dirname.count(os.sep)\n",
        "    for dirpath, dirnames, filenames in os.walk(dirname):\n",
        "        if dirpath.count(os.sep) - initial_depth > 1:\n",
        "            continue\n",
        "        for fname in filenames:\n",
        "            if fname.endswith(\".jpg\"):\n",
        "                photo_id = fname[:-4].replace('_',' ').split()\n",
        "                person_id = ' '.join(photo_id[:-1])\n",
        "                photo_number = int(photo_id[-1])\n",
        "                fpath = os.path.join(dirpath, fname)\n",
        "                photo_ids.append({'person':person_id,'imagenum':photo_number,'photo_path':fpath})\n",
        "\n",
        "    photo_ids = pd.DataFrame(photo_ids)\n",
        "\n",
        "    # mass-merge\n",
        "    # (photos now have same order as attributes)\n",
        "    df = pd.merge(df_attrs,photo_ids,on=('person','imagenum'))\n",
        "\n",
        "    assert len(df)==len(df_attrs),\"lost some data when merging dataframes\"\n",
        "\n",
        "    #image preprocessing\n",
        "    all_photos =df['photo_path'].apply(imread)\\\n",
        "                                .apply(lambda img:img[dy:-dy,dx:-dx])\\\n",
        "                                .apply(lambda img: Image.fromarray(img).resize([dimx,dimy]) )\n",
        "\n",
        "    all_photos = np.stack(all_photos.values).astype('uint8')\n",
        "    all_attrs = df.drop([\"photo_path\",\"person\",\"imagenum\"], axis=1)\n",
        "\n",
        "    return all_photos, all_attrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyFG9F6b_P1R"
      },
      "outputs": [],
      "source": [
        "# Fetch the datasets of faces\n",
        "\n",
        "#%env CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "plt.rcParams.update({'axes.titlesize': 'small'})\n",
        "\n",
        "# a utility to load the dataset\n",
        "data, _ = fetch_lfw_dataset(dimx=36, dimy=36,\n",
        "                            images_name=\"lfw_funneled\",\n",
        "                            attrs_name=\"lfw_attributes.txt\",\n",
        "                            )\n",
        "\n",
        "# preprocess faces\n",
        "data = np.float32(data)/255.\n",
        "\n",
        "IMG_SHAPE = data.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "T1-_inEph8dO",
        "outputId": "42a67b28-6041-47de-88e7-5754f13daeb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-ab06be3d0d68>:7: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
            "  plt.subplot(1,5,i+1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1800 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# show some random (real) faces from our dataset\n",
        "\n",
        "plt.figure(figsize=[18, 18])\n",
        "plt.axis('off');\n",
        "\n",
        "for i in range(5):\n",
        "  plt.subplot(1,5,i+1)\n",
        "  plt.imshow(data[np.random.randint(data.shape[0])], cmap=\"gray\", interpolation=\"none\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuCdxa1wGT2K"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Please don't run tensorfow without this config. Without it you'll take the whole memory of the GPU\n",
        "# and make it unusable by anyone else\n",
        "#gpu_options = tf.GPUOptions(allow_growth=True)\n",
        "#sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
        "# Edit: for colab, resources are limited on the server-side. Go hog.\n",
        "sess = tf.compat.v1.InteractiveSession()\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "#tf.compat.v1.disable_v2_behavior()\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import layers as L\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.InteractiveSession(config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lXI9Kz0rKZ5",
        "outputId": "37bfac2b-8ae3-414f-8027-53471f0bfe94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py:1793: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJBCdp7qgy4L"
      },
      "source": [
        "If we can't tell good faces from bad, we delegate it to yet another neural network!\n",
        "\n",
        "That makes two of them:\n",
        "- Generator - takes random noise for inspiration and tries to generate a face sample. Let's call him G(z), where z is a gaussian noize.\n",
        "\n",
        "- Discriminator - takes a face sample and tries to tell if it's real or fake. Predicts the probability of input image being a real face. Let's call him D(x), x being an image. D(x) is a prediction for real image and D(G(z)) is prediction for the face made by generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJEchmd_VM9b"
      },
      "outputs": [],
      "source": [
        "# Now it's your choise which GAN to build: Jensen-Shannon, or Wasserstein\n",
        "# In addition to the theoretical difference, a couple of practical matters:\n",
        "#  Jensen-Shannon GAN should learn several times faster, but is more sensitive to mode collapse and vanishing gradients.\n",
        "#  Wasserstein GAN doesn't go well in company of batch normalization and ELU activation.\n",
        "\n",
        "GAN_TYPE = \"Jensen-Shannon\"\n",
        "#GAN_TYPE = \"Wasserstein\"\n",
        "\n",
        "# Activations experimentally selected. Will most likely work\n",
        "# for other combinations of activations/architectures\n",
        "if GAN_TYPE == \"Wasserstein\":\n",
        "    generator_activation = partial(keras.activations.relu, alpha=0)\n",
        "elif GAN_TYPE == \"Jensen-Shannon\":\n",
        "    generator_activation = keras.activations.elu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRx7OqROqrEq"
      },
      "source": [
        "# Make the Generator.\n",
        "It takes a random sample as input (size CODE_SIZE) and generates a face with FIGURE_SIZE output size.\n",
        "\n",
        "To enlarge from CODE_SIZE to FIGURE_SIZE (#pix_x by #pix_y by #rgb) you need to use some Deconvolution2D and UpSampling2D layers.\n",
        "\n",
        "To complete the Generator network, I needed to add layers that upscale the input noise vector to the desired output image size. I used Conv2DTranspose layers for this purpose, which perform the inverse operation of Conv2D layers. Additionally, I applied activation functions specified by the generator_activation variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmhRHv4A70LK",
        "outputId": "ca847a53-ad6c-4ee1-a6de-e797bd34dcd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                3084      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 1, 12)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 1, 1, 128)         13952     \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2  (None, 4, 4, 128)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 4, 4, 64)          73792     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSamplin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 36, 36, 32)        18464     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 36, 36, 3)         867       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 110159 (430.31 KB)\n",
            "Trainable params: 110159 (430.31 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Input, Dense, Reshape, Conv2DTranspose, UpSampling2D\n",
        "from keras.models import Model\n",
        "generator_activation = keras.activations.elu\n",
        "\n",
        "# Define CODE_SIZE and FIGURE_SIZE\n",
        "CODE_SIZE = 256\n",
        "FIGURE_SIZE = (36, 36, 3)  # 36x36 image with 3 channels (RGB)\n",
        "\n",
        "with tf.name_scope(\"Generator\"):\n",
        "    generator = Sequential(name=\"Generator\")\n",
        "    generator.add(L.InputLayer([CODE_SIZE],name='noise'))\n",
        "    generator.add(L.Dense(1*1*12, activation=generator_activation))  # Start with a dense layer\n",
        "\n",
        "    # Reshape the output to\n",
        "    generator.add(L.Reshape((1, 1, 12)))\n",
        "\n",
        "    # Upsampling layers\n",
        "    generator.add(L.Conv2DTranspose(128, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "    generator.add(L.UpSampling2D(size=(4, 4)))  # Upsample to (12, 12, 6)\n",
        "    generator.add(L.Conv2DTranspose(64, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "    generator.add(L.UpSampling2D(size=(9, 9)))  # Upsample to (36, 36, 3)\n",
        "    generator.add(L.Conv2DTranspose(32, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "\n",
        "    # Final convolutional layer to get output shape (36, 36, 3)\n",
        "    generator.add(L.Conv2D(3, kernel_size=3, padding='same', activation='tanh'))\n",
        "\n",
        "    assert generator.output_shape[1:] == IMG_SHAPE, \\\n",
        "        f\"generator must output an image of shape {IMG_SHAPE}, but instead it produces {generator.output_shape[1:]}\"\n",
        "\n",
        "    generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJOZFU_dqPD8"
      },
      "source": [
        "# Make the Discriminator.\n",
        "\n",
        "It is your usual convolutional network with interlooping convolution and pooling layers: It takes a figure as input, and a simple output to separate \"Yes\" (figure is real) and \"No\" (figure is fake).The network does not include dropout/batchnorm to avoid learning complications.\n",
        "We also regularize the pre-output layer to prevent discriminator from being too certain.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Define the activation function for the discriminator\n",
        "discriminator_activation = partial(keras.activations.relu, alpha=0.3)\n",
        "\n",
        "# Modify the architecture of the discriminator to include batch normalization\n",
        "with tf.name_scope(\"Discriminator\"):\n",
        "    discriminator = Sequential(name=\"Discriminator\")\n",
        "    discriminator.add(L.InputLayer(IMG_SHAPE))\n",
        "\n",
        "    discriminator.add(Conv2D(32, kernel_size=3, activation=discriminator_activation, padding='same'))\n",
        "    discriminator.add(BatchNormalization())\n",
        "    discriminator.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "    discriminator.add(Conv2D(64, kernel_size=3, activation=discriminator_activation, padding='same'))\n",
        "    discriminator.add(BatchNormalization())\n",
        "    discriminator.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "    discriminator.add(Conv2D(128, kernel_size=3, activation=discriminator_activation, padding='same'))\n",
        "    discriminator.add(BatchNormalization())\n",
        "    discriminator.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "    discriminator.add(Flatten())\n",
        "    discriminator.add(Dense(256, activation=discriminator_activation))\n",
        "    discriminator.add(Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "    if GAN_TYPE == \"Wasserstein\":\n",
        "        # Wasserstein discriminator values are unconstrained\n",
        "        discriminator.add(L.Dense(1))\n",
        "    elif GAN_TYPE == \"Jensen-Shannon\":\n",
        "        # Jensen-Shannon expects probabilities\n",
        "        discriminator.add(L.Dense(2, activation=tf.nn.log_softmax))\n",
        "\n",
        "    discriminator.summary()\n",
        "\n",
        "# Adjust learning rate for discriminator optimizer\n",
        "disc_learning_rate = 1e-4\n",
        "\n",
        "# Use Adam optimizer for discriminator training\n",
        "disc_optimizer = tf.keras.optimizers.Adam(disc_learning_rate, beta1=0.5)\n",
        "\n",
        "# Add dropout layers to the discriminator\n",
        "discriminator.add(Dropout(0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7wmMJiLFyEXc",
        "outputId": "3dd6e1d0-c271-4ec5-fe7d-26f1818125ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 36, 36, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 36, 36, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 18, 18, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 18, 18, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 18, 18, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 9, 9, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 9, 9, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 619208 (2.36 MB)\n",
            "Trainable params: 618760 (2.36 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "beta1 is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d5168a3087f9>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Use Adam optimizer for discriminator training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mdisc_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Add dropout layers to the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     ):\n\u001b[0;32m--> 110\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mesh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m   1085\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iteration_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_iteration_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_process_kwargs\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 )\n\u001b[1;32m    141\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    143\u001b[0m                     \u001b[0;34mf\"{k} is not a valid argument, kwargs should be empty \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0;34m\" for `optimizer_experimental.Optimizer`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: beta1 is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O-mJFIVWDzP"
      },
      "outputs": [],
      "source": [
        "# Helper function to create a shuffling image stream for training\n",
        "\n",
        "def get_tf_dataset(dataset, batch_size):\n",
        "    \"\"\"\n",
        "    Produces an infinite stram of Tensorflow batches from a numpy dataset. The dataset is shuffled every epoch.\n",
        "    Args:\n",
        "       dataset: np.array[n_examples, ...]\n",
        "       batch_size: int, batch size of the results\n",
        "    Reuturns:\n",
        "       Tensor, containing the next batch\n",
        "    \"\"\"\n",
        "    if isinstance(dataset, tf.Tensor):\n",
        "        N_EXAMPLES = dataset.shape[0]\n",
        "    else:\n",
        "        N_EXAMPLES = dataset[0].shape[0]\n",
        "    shuffler = tf.data.experimental.shuffle_and_repeat(N_EXAMPLES)\n",
        "    dataset_tf = tf.data.Dataset.from_tensor_slices(dataset)\n",
        "    suffled_ds = shuffler(dataset_tf)\n",
        "    #return suffled_ds.batch(batch_size).prefetch(1).make_one_shot_iterator().get_next()\n",
        "    return tf.compat.v1.data.make_one_shot_iterator( suffled_ds.batch(batch_size) ).get_next()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzBIUJVNWc8t"
      },
      "outputs": [],
      "source": [
        "# Initialize training data setup.\n",
        "\n",
        "# Notes on strategy: we will train the two networks concurrently:\n",
        "#  - Train discriminator to better distinguish real data from current generator\n",
        "#  - Train generator to make discriminator think generator is real\n",
        "# Since discriminator is a differentiable neural network, we train both with gradient descent.\n",
        "# Training is done iteratively until discriminator is no longer able to find the difference (or until you run out of patience).\n",
        "# Tricks:\n",
        "# Train generator with adam to speed up training. Discriminator trains with SGD to avoid problems with momentum.\n",
        "# More: https://github.com/soumith/ganhacks\n",
        "\n",
        "# Obtain the training data faces stream for the discriminator\n",
        "train_batch_size = 100\n",
        "real_data = get_tf_dataset(data, train_batch_size)\n",
        "\n",
        "# Generate the noise data to be used in the generator training\n",
        "noise_batch_size = tf.compat.v1.placeholder(tf.int32, shape=[], name=\"noise_batch_size\")\n",
        "noise = tf.random.normal([noise_batch_size, CODE_SIZE], dtype=tf.float32, name=\"noise\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wmhAaGiWjoE"
      },
      "outputs": [],
      "source": [
        "with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "\n",
        "  # Run data and noise through the networks\n",
        "  discriminator_real = discriminator(real_data)\n",
        "  generated_data = generator(noise)\n",
        "  discriminator_generated = discriminator(generated_data)\n",
        "\n",
        "  # Configure custom learning and loss details, specific to the GAN strategy type\n",
        "\n",
        "  if GAN_TYPE == \"Wasserstein\":\n",
        "    with tf.name_scope(\"gradient_loss\"):\n",
        "        alpha = tf.random_uniform(shape=[tf.shape(generated_data)[0], 1, 1, 1], minval=0., maxval=1.)\n",
        "        interpolates = alpha*real_data + ((1.-alpha)*generated_data)\n",
        "        disc_interpolates = discriminator(interpolates)\n",
        "        gradients = tf.gradients(disc_interpolates, [interpolates])[0]\n",
        "        slopes = tf.norm(tf.reshape(gradients, [tf.shape(gradients)[0], -1]), axis=1)\n",
        "        gradient_penalty = tf.reduce_mean(tf.square(slopes - 1.))\n",
        "    EMD_loss = tf.reduce_mean(discriminator_generated) - tf.reduce_mean(discriminator_real)\n",
        "    LAMBDA = 10.\n",
        "    discriminator_loss = EMD_loss + LAMBDA*gradient_penalty\n",
        "    generator_loss = -tf.reduce_mean(discriminator_generated)\n",
        "\n",
        "  if GAN_TYPE == \"Jensen-Shannon\":\n",
        "    logp_real = discriminator(real_data)\n",
        "    logp_gen = discriminator(generated_data)\n",
        "    discriminator_loss = -tf.reduce_mean(logp_real[:,1] + logp_gen[:,0])\n",
        "    generator_loss = -tf.reduce_mean(logp_gen[:,1])\n",
        "\n",
        "# Get gradients\n",
        "disc_grads = disc_tape.gradient(discriminator_loss, discriminator.trainable_weights)\n",
        "gen_grads  = gen_tape.gradient(generator_loss, generator.trainable_weights)\n",
        "\n",
        "# Define the optimizer for both networks.\n",
        "# The values below are rough suggestions aimed at not exploding a discriminator\n",
        "# of complexity roughly equal to the complexity of the generator.\n",
        "disc_learning_rate = 1e-3\n",
        "\n",
        "if GAN_TYPE == \"Wasserstein\":\n",
        "    # https://arxiv.org/pdf/1704.00028.pdf\n",
        "    #disc_optimizer = tf.keras.optimizers.Adam(disc_learning_rate, beta1=0, beta2=0.9).minimize(\n",
        "    #      discriminator_loss, var_list=discriminator.trainable_weights)\n",
        "    disc_optimizer = tf.keras.optimizers.Adam(disc_learning_rate, beta1=0, beta2=0.9).apply_gradients(\n",
        "        zip(disc_grads, discriminator.trainable_weights))\n",
        "elif GAN_TYPE == \"Jensen-Shannon\":\n",
        "    #disc_optimizer = tf.keras.optimizers.SGD(disc_learning_rate).minimize(\n",
        "    #    discriminator_loss, var_list=discriminator.trainable_weights)\n",
        "    disc_optimizer = tf.keras.optimizers.SGD(disc_learning_rate).apply_gradients(\n",
        "        zip(disc_grads, discriminator.trainable_weights))\n",
        "\n",
        "\n",
        "if GAN_TYPE == \"Wasserstein\":\n",
        "    # https://arxiv.org/pdf/1704.00028.pdf\n",
        "    #gen_optimizer = tf.keras.optimizers.Adam(1e-4, beta1=0, beta2=0.9).minimize(\n",
        "    #    generator_loss, var_list=generator.trainable_weights)\n",
        "    gen_optimizer = tf.keras.optimizers.Adam(1e-4, beta1=0, beta2=0.9).apply_gradients(\n",
        "        zip(gen_grads, generator.trainable_weights))\n",
        "elif GAN_TYPE == \"Jensen-Shannon\":\n",
        "    #gen_optimizer = tf.keras.optimizers.Adam(1e-4).minimize(generator_loss, var_list=generator.trainable_weights)\n",
        "    gen_optimizer = tf.keras.optimizers.Adam(1e-4).apply_gradients(\n",
        "        zip(gen_grads, generator.trainable_weights))\n",
        "\n",
        "learning_summary = tf.compat.v1.summary.merge([\n",
        "    tf.compat.v1.summary.scalar(\"discriminator_loss\", discriminator_loss),\n",
        "    tf.compat.v1.summary.scalar(\"generator_loss\", generator_loss)\n",
        "])\n",
        "\n",
        "images_summary = tf.compat.v1.summary.image(\"generated_images\", generator(noise))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMhPM_fCZ1ES"
      },
      "outputs": [],
      "source": [
        "# initialize all variables.\n",
        "sess.run(tf.compat.v1.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVVcyUnUaGMh"
      },
      "outputs": [],
      "source": [
        "# Define helper functions to evaluate the Gen. and Disc. over some data batches\n",
        "\n",
        "def sample_noise_batch(bsize):\n",
        "    # Get a new batch of noise samples\n",
        "    return np.random.normal(size=(bsize, CODE_SIZE)).astype('float32')\n",
        "\n",
        "def sample_data_batch(bsize):\n",
        "    # Get a batch of real faces\n",
        "    idxs = np.random.choice(np.arange(data.shape[0]), size=bsize)\n",
        "    return data[idxs]\n",
        "\n",
        "def sample_images(nrow,ncol, sharp=False):\n",
        "    # Let the generator create some faces from noise and show them\n",
        "    images = generator.predict(sample_noise_batch(bsize=nrow*ncol))\n",
        "    if np.var(images) != 0:\n",
        "        images = images.clip(np.min(data),np.max(data))\n",
        "    for i in range(nrow*ncol):\n",
        "        plt.subplot(nrow,ncol,i+1)\n",
        "        if sharp:\n",
        "            plt.imshow(images[i].reshape(IMG_SHAPE), cmap=\"gray\", interpolation=\"none\")\n",
        "        else:\n",
        "            plt.imshow(images[i].reshape(IMG_SHAPE), cmap=\"gray\")\n",
        "        plt.axis('off')\n",
        "\n",
        "def sample_probas(bsize):\n",
        "    # Let the discriminator predict 'True' or 'False' label for some real and some generated faces.\n",
        "    #  (note that this is actually a continuous number - a sort of 'probability')\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_title('Generated vs real data')\n",
        "    ax.hist(discriminator.predict(sample_data_batch(bsize)).ravel(),\n",
        "             label='D(x)', alpha=0.5, density=True)\n",
        "    ax.hist(discriminator.predict(generator.predict(sample_noise_batch(bsize))).ravel(),\n",
        "             label='D(G(z))', alpha=0.5,  density=True)\n",
        "    ax.legend(loc='best')\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz5LzfqtaKIt"
      },
      "outputs": [],
      "source": [
        "# Actual training\n",
        "\n",
        "from IPython import display\n",
        "import os\n",
        "\n",
        "LOGDIR = \"./\"\n",
        "MODEL_NAME = \"faces_GAN_%s_noreg_v1\" % GAN_TYPE\n",
        "MODEL_DIR = \"./\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "MODEL_WEIGHTS_FILE =  os.path.join(MODEL_DIR, (\"%s.ckpt\" % MODEL_NAME))\n",
        "VALIDATION_INTERVAL = 50 # time between intermediate visual updates.\n",
        "TOTAL_ITERATIONS = int(5e3) # was 5e4 but colab takes too long\n",
        "# Number of discriminator training iterations per generator iteration\n",
        "# In our tests for discriminator of roughly as complexity as discriminator\n",
        "# 5 worked for both Wasserstein and Jensen–Shannon.\n",
        "DISCRIMINATOR_ITERATIONS = 5\n",
        "\n",
        "# Save the intermediate weights, such that if our training gets interrupted,\n",
        "#  We don't have to restart from scratch.\n",
        "train_writer = tf.compat.v1.summary.FileWriter(os.path.join(LOGDIR, MODEL_NAME, \"train\"))\n",
        "train_writer.add_graph(tf.compat.v1.get_default_graph())\n",
        "weights_saver = tf.compat.v1.train.Saver()\n",
        "\n",
        "if(os.path.exists(MODEL_WEIGHTS_FILE)) :\n",
        "  try:\n",
        "    weights_saver.restore(sess, MODEL_WEIGHTS_FILE)\n",
        "  except (tf.errors.NotFoundError, tf.errors.InvalidArgumentError):\n",
        "    print(\"Can't restore parameters: no file with weights\")\n",
        "\n",
        "\n",
        "for epoch in range(TOTAL_ITERATIONS):\n",
        "    for i in range(DISCRIMINATOR_ITERATIONS):\n",
        "        # Train the discriminator\n",
        "        sess.run(disc_optimizer, {noise_batch_size: train_batch_size})\n",
        "    # Train the generator\n",
        "    summary, _ = sess.run([learning_summary, gen_optimizer], {noise_batch_size: train_batch_size})\n",
        "\n",
        "    # write the updated weights\n",
        "    train_writer.add_summary(summary, epoch)\n",
        "\n",
        "    if epoch % VALIDATION_INTERVAL == 0:\n",
        "        # display intermediate status and some generated faces.\n",
        "        display.clear_output(wait=False)\n",
        "        weights_saver.save(sess, MODEL_WEIGHTS_FILE)\n",
        "        epoch_images_summary = sess.run(images_summary, {noise_batch_size: 3})\n",
        "        train_writer.add_summary(epoch_images_summary, epoch)\n",
        "        sample_images(2, 3, True)\n",
        "        fig, ax = sample_probas(1000)\n",
        "        ax.set_title((\"Epoch %i; \" % epoch) + ax.get_title())\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H09ukireaN9R"
      },
      "outputs": [],
      "source": [
        "## Show us some generated faces after our training!\n",
        "plt.figure(figsize=[16, 24])\n",
        "sample_images(16, 8);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFvnr1R98B_z"
      },
      "source": [
        "#EXTRA\n",
        "1. TRYING WITH DENSER STARTING LAYERS:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEFqK_mH8CfB"
      },
      "source": [
        "Total params: 5717315 (21.81 MB) Trainable params: 5717315 (21.81 MB) Non-trainable params: 0 (0.00 Byte)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCl0Xfu5asBX"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Dense, Reshape, Conv2DTranspose, UpSampling2D\n",
        "from keras.models import Model\n",
        "generator_activation = keras.activations.elu\n",
        "\n",
        "# Define CODE_SIZE and FIGURE_SIZE\n",
        "CODE_SIZE = 256\n",
        "FIGURE_SIZE = (36, 36, 3)  # 36x36 image with 3 channels (RGB)\n",
        "\n",
        "with tf.name_scope(\"Generator\"):\n",
        "    generator = Sequential(name=\"Generator\")\n",
        "    generator.add(L.InputLayer([CODE_SIZE],name='noise'))\n",
        "    generator.add(L.Dense(9*9*256, activation=generator_activation))  # Start with a dense layer\n",
        "\n",
        "    # Reshape the output to (9, 9, 256)\n",
        "    generator.add(L.Reshape((9, 9, 256)))\n",
        "\n",
        "    # Upsampling layers\n",
        "    generator.add(L.Conv2DTranspose(128, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "    generator.add(L.UpSampling2D(size=(2, 2)))  # Upsample to (18, 18, 128)\n",
        "    generator.add(L.Conv2DTranspose(64, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "    generator.add(L.UpSampling2D(size=(2, 2)))  # Upsample to (36, 36, 64)\n",
        "    generator.add(L.Conv2DTranspose(32, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "\n",
        "    # Final convolutional layer to get output shape (36, 36, 3)\n",
        "    generator.add(L.Conv2D(3, kernel_size=3, padding='same', activation='tanh'))\n",
        "\n",
        "    assert generator.output_shape[1:] == IMG_SHAPE, \\\n",
        "        f\"generator must output an image of shape {IMG_SHAPE}, but instead it produces {generator.output_shape[1:]}\"\n",
        "\n",
        "    generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyVPUMuL8Dy4"
      },
      "source": [
        "Total params: 156419 (611.01 KB)\n",
        "Trainable params: 156419 (611.01 KB)\n",
        "Non-trainable params: 0 (0.00 Byte)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMid33Y28OE9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define CODE_SIZE and FIGURE_SIZE\n",
        "CODE_SIZE = 256\n",
        "FIGURE_SIZE = (36, 36, 3)  # 36x36 image with 3 channels (RGB)\n",
        "\n",
        "with tf.name_scope(\"Generator\"):\n",
        "    generator = Sequential(name=\"Generator\")\n",
        "    generator.add(L.InputLayer([CODE_SIZE],name='noise'))\n",
        "    generator.add(L.Dense(4*4*12, activation=generator_activation))  # Start with a dense layer\n",
        "\n",
        "    # Reshape the output to\n",
        "    generator.add(L.Reshape((4, 4, 12)))\n",
        "\n",
        "    # Upsampling layers\n",
        "    generator.add(L.Conv2DTranspose(128, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "    generator.add(L.UpSampling2D(size=(3, 3)))  # Upsample to (12, 12, 6)\n",
        "    generator.add(L.Conv2DTranspose(64, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "    generator.add(L.UpSampling2D(size=(3, 3)))  # Upsample to (36, 36, 3)\n",
        "    generator.add(L.Conv2DTranspose(32, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "\n",
        "    # Final convolutional layer to get output shape (36, 36, 3)\n",
        "    generator.add(L.Conv2D(3, kernel_size=3, padding='same', activation='tanh'))\n",
        "\n",
        "    assert generator.output_shape[1:] == IMG_SHAPE, \\\n",
        "        f\"generator must output an image of shape {IMG_SHAPE}, but instead it produces {generator.output_shape[1:]}\"\n",
        "\n",
        "    generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conditional GAN with Attribute Labels:\n",
        "\n",
        "Modify your GAN architecture to be conditional on attribute labels. You can train the model to generate faces with specific attributes like gender, age, hair color, facial expression, etc. This allows you to control which features are present in the generated faces by providing corresponding attribute labels during training."
      ],
      "metadata": {
        "id": "dyw7wOIz3Ng7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dimensionality of attribute labels\n",
        "NUM_ATTRIBUTES = 4  # Example: Gender, Age, Hair Color, Facial Expression\n",
        "\n",
        "# Generator architecture modification\n",
        "with tf.name_scope(\"Conditional_Generator\"):\n",
        "    noise_input = L.Input(shape=(CODE_SIZE,), name='noise_input')\n",
        "    attribute_input = L.Input(shape=(NUM_ATTRIBUTES,), name='attribute_input')\n",
        "\n",
        "    # Concatenate noise and attribute labels\n",
        "    merged_input = L.concatenate([noise_input, attribute_input], axis=1)\n",
        "\n",
        "    generator = Sequential(name=\"Generator\")\n",
        "    generator.add(L.Dense(1*1*12, activation=generator_activation, input_shape=(CODE_SIZE + NUM_ATTRIBUTES,)))  # Start with a dense layer\n",
        "\n",
        "    # Reshape the output to\n",
        "    generator.add(L.Reshape((1, 1, 12)))\n",
        "\n",
        "    # Upsampling layers\n",
        "    generator.add(L.Conv2DTranspose(128, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "    generator.add(L.UpSampling2D(size=(4, 4)))  # Upsample to (12, 12, 6)\n",
        "    generator.add(L.Conv2DTranspose(64, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "    generator.add(L.UpSampling2D(size=(9, 9)))  # Upsample to (36, 36, 3)\n",
        "    generator.add(L.Conv2DTranspose(32, kernel_size=3, strides=1, padding='same', activation=generator_activation))\n",
        "\n",
        "    # Final convolutional layer to get output shape (36, 36, 3)\n",
        "    generator.add(L.Conv2D(3, kernel_size=3, padding='same', activation='tanh'))\n",
        "\n",
        "    assert generator.output_shape[1:] == FIGURE_SIZE, \\\n",
        "        f\"generator must output an image of shape {FIGURE_SIZE}, but instead it produces {generator.output_shape[1:]}\"\n",
        "\n",
        "    generator_model = Model(inputs=[noise_input, attribute_input], outputs=generator([noise_input, attribute_input]))\n",
        "\n",
        "    generator_model.summary()"
      ],
      "metadata": {
        "id": "KDRG84gX3uIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator architecture modification\n",
        "with tf.name_scope(\"Conditional_Discriminator\"):\n",
        "    image_input = L.Input(shape=FIGURE_SIZE, name='image_input')\n",
        "    attribute_input = L.Input(shape=(NUM_ATTRIBUTES,), name='attribute_input')\n",
        "\n",
        "    discriminator = Sequential(name=\"Discriminator\")\n",
        "    discriminator.add(image_input)\n",
        "\n",
        "    discriminator.add(Conv2D(32, kernel_size=3, activation=discriminator_activation, padding='same'))\n",
        "    discriminator.add(BatchNormalization())\n",
        "    discriminator.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "    discriminator.add(Conv2D(64, kernel_size=3, activation=discriminator_activation, padding='same'))\n",
        "    discriminator.add(BatchNormalization())\n",
        "    discriminator.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "    discriminator.add(Conv2D(128, kernel_size=3, activation=discriminator_activation, padding='same'))\n",
        "    discriminator.add(BatchNormalization())\n",
        "    discriminator.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "    discriminator.add(Flatten())\n",
        "    discriminator.add(Dense(256, activation=discriminator_activation))\n",
        "\n",
        "    # Concatenate attribute labels with discriminator features\n",
        "    merged_features = L.concatenate([discriminator.output, attribute_input])\n",
        "\n",
        "    discriminator.add(Dense(2, activation='softmax'))  # Output 2 classes: real or fake\n",
        "\n",
        "    discriminator_model = Model(inputs=[image_input, attribute_input], outputs=discriminator([image_input, attribute_input]))\n",
        "\n",
        "    discriminator_model.summary()"
      ],
      "metadata": {
        "id": "8C1iXl6j3QdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the models\n",
        "discriminator_model.compile(optimizer=disc_optimizer, loss='binary_crossentropy')\n",
        "\n",
        "# Combined GAN model\n",
        "noise = L.Input(shape=(CODE_SIZE,), name='noise')\n",
        "attribute = L.Input(shape=(NUM_ATTRIBUTES,), name='attribute')\n",
        "\n",
        "fake_image = generator_model([noise, attribute])\n",
        "discriminator_model.trainable = False\n",
        "validity = discriminator_model([fake_image, attribute])\n",
        "\n",
        "combined_model = Model(inputs=[noise, attribute], outputs=validity)\n",
        "combined_model.compile(optimizer=gen_optimizer, loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "-2YXvIPl308F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}